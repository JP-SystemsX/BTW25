{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3783a-8006-4da6-8709-a2de47ccc118",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/amazon-science/chronos-forecasting.git\n",
    "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "id": "5aaeab1e-7091-4b64-9cc1-3e1bf426cb1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T13:28:45.620705Z",
     "start_time": "2024-10-02T13:28:34.184208Z"
    }
   },
   "source": [
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Literal, Optional, Tuple, Union\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    GenerationConfig,\n",
    "    PreTrainedModel,\n",
    ")\n",
    "from chronos import ChronosConfig, ChronosTokenizer, MeanScaleUniformBins, ChronosModel, ChronosPipeline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "24b0896e-1f69-45cb-8721-93228bf25d70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T13:28:46.715913Z",
     "start_time": "2024-10-02T13:28:46.710913Z"
    }
   },
   "source": [
    "def left_pad_and_stack_1D(tensors: List[torch.Tensor]):\n",
    "    max_len = max(len(c) for c in tensors)\n",
    "    padded = []\n",
    "    for c in tensors:\n",
    "        assert isinstance(c, torch.Tensor)\n",
    "        assert c.ndim == 1\n",
    "        padding = torch.full(\n",
    "            size=(max_len - len(c),), fill_value=torch.nan, device=c.device\n",
    "        )\n",
    "        padded.append(torch.concat((padding, c), dim=-1))\n",
    "    return torch.stack(padded)\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "6de35767-4552-4081-91f7-020199286d9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T13:28:48.378417Z",
     "start_time": "2024-10-02T13:28:47.190758Z"
    }
   },
   "source": [
    "# from chronos import ChronosPipeline\n",
    "import torch\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"cpu\",  # use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model=pipeline.model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\poehlmann\\PycharmProjects\\BTW25\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "e98dbbb5-d867-4735-86dd-6b049d3119b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T13:28:50.105667Z",
     "start_time": "2024-10-02T13:28:48.382418Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\")\n",
    "\n",
    "context = torch.tensor(df[\"#Passengers\"])\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"amazon/chronos-t5-small\",\n",
    "    device_map=\"cuda\",  # use \"cpu\" for CPU inference and \"mps\" for Apple Silicon\n",
    "    torch_dtype=torch.bfloat16)\n",
    "\n",
    "chronos_config = ChronosConfig(**config.chronos_config)\n",
    "tokenizer=chronos_config.create_tokenizer()\n",
    "\n",
    "context_tensor = pipeline._prepare_and_validate_context(context)\n",
    "token_ids, attention_mask, scale = tokenizer.context_input_transform(context_tensor)\n",
    "scale\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\poehlmann\\PycharmProjects\\BTW25\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([280.2986])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "277171bc-ba25-4411-baf0-41735b835ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T13:28:50.121543Z",
     "start_time": "2024-10-02T13:28:50.107540Z"
    }
   },
   "source": [
    "class UnivariateTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, series, sequence_length, prediction_length):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            series (Tensor): A tensor containing the time series data.\n",
    "            sequence_length (int): The number of time steps to use as input.\n",
    "            prediction_length (int): The number of time steps to predict.\n",
    "        \"\"\"\n",
    "        self.series = series\n",
    "        self.sequence_length = sequence_length\n",
    "        self.prediction_length = prediction_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.series) - self.sequence_length - self.prediction_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        idx is the starting point, we slice the sequence length for input\n",
    "        and slice the prediction length for target output\n",
    "        '''\n",
    "        x = self.series[idx:idx + self.sequence_length]\n",
    "        y = self.series[idx + self.sequence_length:idx + self.sequence_length + self.prediction_length]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "sequence_length = 10  # Length of the input sequence\n",
    "prediction_length = 5  # Length of the output sequence you want to predict\n",
    "# Convert data array to a torch tensor\n",
    "time_series_tensor = torch.tensor(df[\"#Passengers\"], dtype=torch.float32)  \n",
    "\n",
    "dataset = UnivariateTimeSeriesDataset(time_series_tensor, sequence_length, prediction_length)\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "train_data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "14cba0b0-e4d6-4e7b-b53f-75f6ada59a70",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-02T13:28:50.123558Z"
    }
   },
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Enable trainable parameters\n",
    "model.train()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in tqdm(range(5)):\n",
    "    for inputs, targets in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        token_ids, attention_mask, scale = tokenizer.context_input_transform(inputs)\n",
    "\n",
    "        samples = model(\n",
    "                token_ids,\n",
    "                attention_mask,\n",
    "                prediction_length,\n",
    "                num_samples=30,\n",
    "                temperature=1.0,\n",
    "                top_k=50,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "\n",
    "        predictions = []\n",
    "        remaining = prediction_length\n",
    "\n",
    "        while remaining > 0:\n",
    "            token_ids, attention_mask, scale = tokenizer.context_input_transform(inputs)\n",
    "\n",
    "            prediction = tokenizer.output_transform(\n",
    "                samples, scale\n",
    "            )\n",
    "\n",
    "            predictions.append(prediction.median(dim=1))\n",
    "            remaining -= prediction.shape[-1]\n",
    "\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "\n",
    "        preds = predictions[0].values.median(dim=1).values\n",
    "        actuals = targets.median(dim=1).values\n",
    "        loss = criterion(preds, actuals)\n",
    "        if not loss.requires_grad:\n",
    "            loss = loss.clone().requires_grad_(True)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}: Loss = {loss.item()}')\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf9d074e0072445aba30fb1c4d854d8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 24.34471321105957\n",
      "Epoch 2: Loss = 1366.2958984375\n",
      "Epoch 3: Loss = 116.33440399169922\n",
      "Epoch 4: Loss = 926.5825805664062\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54b784-07c2-47b2-91e3-22f14be6bb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ccb0a-e636-4a80-b097-ddaa67f7f59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7f62b-de41-4a38-97ba-7617915f2018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
